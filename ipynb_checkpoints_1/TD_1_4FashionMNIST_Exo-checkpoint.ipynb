{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Exercise: Use the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. \n",
    "MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. \n",
    "\n",
    "Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network,\n",
    "and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='TD_images/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "\n",
    "\n",
    "## load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper1\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper1.imshow(image[11,:]);\n",
    "#see different items "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exo1: Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, \n",
    "each image is 28x28 which is a total of 784 pixels, \n",
    "and there are 10 classes. \n",
    "You should include at least one hidden layer. \n",
    "\n",
    "Suggest:  use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. \n",
    "\n",
    "It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.30364992380587025\n",
      "Training loss: 0.2960661815157704\n",
      "Training loss: 0.28186562836869183\n",
      "Training loss: 0.2756728691332884\n",
      "Training loss: 0.2674575387510155\n",
      "Training loss: 0.26058686059564035\n",
      "Training loss: 0.25051197017243165\n",
      "Training loss: 0.2544397397209078\n",
      "Training loss: 0.24238835539279588\n",
      "Training loss: 0.23464068470161353\n",
      "Training loss: 0.23165905531217804\n",
      "Training loss: 0.224796623726294\n",
      "Training loss: 0.22394911853918262\n",
      "Training loss: 0.21802461264865486\n",
      "Training loss: 0.2177069007651384\n",
      "Training loss: 0.21062175759962246\n",
      "Training loss: 0.2049230106516497\n",
      "Training loss: 0.2019343167535468\n",
      "Training loss: 0.20416986111845417\n",
      "Training loss: 0.20477006228160122\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "epochs = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b0ce1275b2b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"InlineBackend.figure_format = 'retina'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Test out your network!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "\n",
    "# Convert 2D image to 1D vector\n",
    "\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "#ps =\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
